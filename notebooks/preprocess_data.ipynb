{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izHj9uno-xw-"
   },
   "source": [
    "# import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q57zqGCX-xxB"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "from torch import nn\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0RhP6ihg-xxC"
   },
   "source": [
    "# preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1166,
     "status": "ok",
     "timestamp": 1701125499783,
     "user": {
      "displayName": "건건",
      "userId": "00925943111472079574"
     },
     "user_tz": 300
    },
    "id": "XRWZyrTQ_eFH",
    "outputId": "5540d413-8f1d-4e44-9b98-07691420cb91"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J_-VmgVm_ksL"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"/content/drive/MyDrive/NLP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ywqzSFVV-xxD"
   },
   "outputs": [],
   "source": [
    "with open(\"../data/english-train.json\", \"r\") as json_file:\n",
    "    english_train = json.load(json_file)\n",
    "with open(\"../data/english-dev.json\", \"r\") as json_file:\n",
    "    english_dev = json.load(json_file)\n",
    "with open(\"../data/english-test.json\", \"r\") as json_file:\n",
    "    english_test = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1701125499784,
     "user": {
      "displayName": "건건",
      "userId": "00925943111472079574"
     },
     "user_tz": 300
    },
    "id": "5g0jggRHDASX",
    "outputId": "44a582ca-5cf2-443a-8078-e5f4a84a309a"
   },
   "outputs": [],
   "source": [
    "english_dev[0][\"utterances\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t4lBFvpG-xxD"
   },
   "outputs": [],
   "source": [
    "patient_ques = []\n",
    "docter_ans = []\n",
    "\n",
    "patient_ques.extend([i[\"utterances\"][0] for i in english_train])\n",
    "docter_ans.extend([i[\"utterances\"][1] for i in english_train])\n",
    "patient_ques.extend([i[\"utterances\"][0] for i in english_dev])\n",
    "docter_ans.extend([i[\"utterances\"][1] for i in english_dev])\n",
    "patient_ques.extend([i[\"utterances\"][0] for i in english_test])\n",
    "docter_ans.extend([i[\"utterances\"][1] for i in english_test])\n",
    "\n",
    "patient_ques = [\"SOS \" + i[9:] + \" EOS\" for i in patient_ques]\n",
    "docter_ans = [\"SOS \" + i[8:] + \" EOS\" for i in docter_ans]\n",
    "\n",
    "tot_data = []\n",
    "tot_data.extend(patient_ques)\n",
    "tot_data.extend(docter_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5106,
     "status": "ok",
     "timestamp": 1701125504884,
     "user": {
      "displayName": "건건",
      "userId": "00925943111472079574"
     },
     "user_tz": 300
    },
    "id": "T84IvYBQCSI7",
    "outputId": "dadab167-a65c-4b76-f26f-a4e5d6245d42"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
    "dialogs = tot_data\n",
    "# Fit the tokenizer on the texts\n",
    "tokenizer.fit_on_texts(dialogs)\n",
    "\n",
    "# Convert texts to sequences of integers\n",
    "patient_ques = tokenizer.texts_to_sequences(patient_ques)\n",
    "docter_ans = tokenizer.texts_to_sequences(docter_ans)\n",
    "\n",
    "# Pad the sequences to have equal length\n",
    "# patient_ques = pad_sequences(patient_ques, padding='post')\n",
    "# docter_ans = pad_sequences(docter_ans, padding='post')\n",
    "\n",
    "print(\"Word Index = \", tokenizer.word_index)\n",
    "print(\"Sequences = \", patient_ques)\n",
    "# print(\"Padded Sequences:\")\n",
    "# print(padded_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xNStX9WFE7MZ"
   },
   "outputs": [],
   "source": [
    "class EmbeddingBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        num_embeddings : the number of word types\n",
    "        embedding_dim : the dimension of embedding vector\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_embeddings, embedding_dim):\n",
    "        super(EmbeddingBlock, self).__init__()\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.pos_units = [\n",
    "            10000 ** (2 * i / self.embedding_dim)\n",
    "            for i in range(self.embedding_dim // 2)\n",
    "        ]\n",
    "\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=num_embeddings, embedding_dim=embedding_dim\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        input : indexed words (batch_size, num_words)\n",
    "        output : word embeddings (batch_size, num_words, embedding_dim)\n",
    "        \"\"\"\n",
    "\n",
    "        out = self.embedding(x)\n",
    "\n",
    "        pos = torch.zeros(out.shape)\n",
    "\n",
    "        for p in range(pos.shape[1]):\n",
    "            for i in range(0, pos.shape[2], 2):\n",
    "                pos[:, p, i] = torch.sin(torch.Tensor([p / self.pos_units[i // 2]]))\n",
    "                pos[:, p, i + 1] = torch.cos(torch.Tensor([p / self.pos_units[i // 2]]))\n",
    "        out += pos\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class AttentionBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        in_channel : the dimension of embedding vector\n",
    "        out_channel : the dimension of query/key/value vector\n",
    "\n",
    "\n",
    "    Variables:\n",
    "        in_channel : d_model\n",
    "        out_channel : d_k\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super(AttentionBlock, self).__init__()\n",
    "\n",
    "        self.in_channel = in_channel\n",
    "\n",
    "        self.fc_q = nn.Linear(in_channel, out_channel)  # W^Q\n",
    "        self.fc_k = nn.Linear(in_channel, out_channel)  # W^K\n",
    "        self.fc_v = nn.Linear(in_channel, out_channel)  # W^V\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, Q, K, V):\n",
    "        \"\"\"\n",
    "        input : embedded words (batch_size, query_dim, key_dim, value_dim)\n",
    "        output : attention score (batch_size, query_dim)\n",
    "        \"\"\"\n",
    "        out_q = self.fc_q(Q)\n",
    "        out_k = self.fc_k(K)\n",
    "        out_v = self.fc_v(V)\n",
    "\n",
    "        out = self.softmax(out_q @ out_k.transpose(1, 2) / math.sqrt(self.in_channel))\n",
    "\n",
    "        out = out @ out_v\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class MultiHeadAttentionBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        in_channel : the dimension of embedding vector\n",
    "        num_attention : the number of attention heads\n",
    "        hidden_channel : the number of hidden channels in Position-wise Feed-Forward Networks\n",
    "\n",
    "    Variables:\n",
    "        in_channel : d_model\n",
    "        inner_channel : d_ff\n",
    "        num_attention : h\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channel, num_attention, hidden_channel):\n",
    "        super(MultiHeadAttentionBlock, self).__init__()\n",
    "\n",
    "        self.num_attention = num_attention\n",
    "\n",
    "        self.heads = nn.ModuleList(\n",
    "            [\n",
    "                AttentionBlock(in_channel, in_channel // self.num_attention)\n",
    "                for _ in range(num_attention)\n",
    "            ]\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.fc = nn.Linear(in_channel, in_channel)  # W^O\n",
    "\n",
    "        self.ln1 = nn.LayerNorm((in_channel))\n",
    "\n",
    "        self.ffc = nn.Sequential(\n",
    "            nn.Linear(\n",
    "                in_channel, hidden_channel\n",
    "            ),  # Position-wise Feed-Forward Networks\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_channel, in_channel),\n",
    "        )\n",
    "\n",
    "        self.ln2 = nn.LayerNorm((in_channel))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        input : indexed words (batch_size, num_words)\n",
    "        output : processed attention scores (batch_size, embedding_dim)\n",
    "        \"\"\"\n",
    "        outs = [self.heads[i](x, x, x) for i in range(self.num_attention)]\n",
    "        out = torch.cat(outs, dim=2)\n",
    "        out = self.fc(out)\n",
    "\n",
    "        out = self.ln1(out + x)\n",
    "\n",
    "        out = self.ln2(out + self.ffc(out))\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class TransformerEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        num_embeddings : the number of word types\n",
    "        num_enc_layers : the number of encoder stack\n",
    "        embedding_dim : the dimension of embedding vector\n",
    "        num_attention : the number of attention heads\n",
    "        hidden_channel : the number of hidden channels in Position-wise Feed-Forward Networks\n",
    "        use_embedding : Transformer embedding enabled or not\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_embeddings,\n",
    "        num_enc_layers=6,\n",
    "        embedding_dim=512,\n",
    "        num_attention=8,\n",
    "        hidden_channel=2048,\n",
    "        use_embedding=True,\n",
    "    ):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "\n",
    "        self.num_enc_layers = num_enc_layers\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_attention = num_attention\n",
    "        self.hidden_channel = hidden_channel\n",
    "        self.use_embedding = use_embedding\n",
    "\n",
    "        if use_embedding:\n",
    "            self.embedding = EmbeddingBlock(num_embeddings, embedding_dim)\n",
    "\n",
    "        self.multihead_attention_blocks = nn.ModuleList(\n",
    "            [\n",
    "                MultiHeadAttentionBlock(\n",
    "                    in_channel=self.embedding_dim,\n",
    "                    num_attention=self.num_attention,\n",
    "                    hidden_channel=self.hidden_channel,\n",
    "                )\n",
    "                for _ in range(self.num_enc_layers)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        input : indexed words (batch_size, num_words)\n",
    "        output : features (batch_size, embedding_dim)\n",
    "        \"\"\"\n",
    "\n",
    "        out = x\n",
    "\n",
    "        if self.use_embedding:\n",
    "            out = self.embedding(x)\n",
    "\n",
    "        for multihead_attention in self.multihead_attention_blocks:\n",
    "            out = multihead_attention(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s8GrVZshFXYj"
   },
   "outputs": [],
   "source": [
    "class SegmentEmbedding(\n",
    "    nn.Embedding\n",
    "):  # referenced from https://github.com/codertimo/BERT-pytorch/blob/master/bert_pytorch/model/embedding/segment.py\n",
    "    def __init__(self, embedding_dim):\n",
    "        super(SegmentEmbedding, self).__init__(3, embedding_dim)\n",
    "\n",
    "\n",
    "class BERTEmbeddingBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        num_embeddings : the number of word types\n",
    "        embedding_dim : the dimension of embedding vector\n",
    "\n",
    "    Variables:\n",
    "        out_channel : d_model\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_embeddings, embedding_dim):\n",
    "        super(BERTEmbeddingBlock, self).__init__()\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.pos_units = [\n",
    "            10000 ** (2 * i / self.embedding_dim)\n",
    "            for i in range(self.embedding_dim // 2)\n",
    "        ]\n",
    "\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=num_embeddings, embedding_dim=embedding_dim\n",
    "        )\n",
    "        self.segment_embedding = SegmentEmbedding(self.embedding_dim)  # 줄여도 될듯\n",
    "\n",
    "    def forward(self, x, segment_info):\n",
    "        \"\"\"\n",
    "        input : indexed words (batch_size, num_words)\n",
    "        output : word embeddings (batch_size, num_words, embedding_dim)\n",
    "        \"\"\"\n",
    "\n",
    "        out = self.embedding(x)  # Tocken Embedding\n",
    "        pos = torch.zeros(out.shape)  # Position Embedding\n",
    "        for p in range(pos.shape[1]):\n",
    "            for i in range(0, pos.shape[2], 2):\n",
    "                pos[:, p, i] = torch.sin(torch.Tensor([p / self.pos_units[i // 2]]))\n",
    "                pos[:, p, i + 1] = torch.cos(torch.Tensor([p / self.pos_units[i // 2]]))\n",
    "        out += pos\n",
    "\n",
    "        out += self.segment_embedding(\n",
    "            segment_info\n",
    "        )  # Segment Embedding   # referenced from https://github.com/codertimo/BERT-pytorch/blob/master/bert_pytorch/model/embedding/segment.py\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class BERT(nn.Module):\n",
    "\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        num_embeddings : the number of word types\n",
    "        num_transformer_block : the dimension of embedding vector\n",
    "        num_enc_layers : the number of encoder stack\n",
    "        embedding_dim : the dimension of embedding vector\n",
    "        num_attention : the number of attention heads\n",
    "        hidden_channel : the number of hidden channels in Position-wise Feed-Forward Networks\n",
    "\n",
    "    Variables:\n",
    "        out_channel : d_model\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_embeddings=30000,\n",
    "        num_transformer_block=6,\n",
    "        num_enc_layers=1,\n",
    "        embedding_dim=768,\n",
    "        num_attention=12,\n",
    "        hidden_channel=3072,\n",
    "    ):\n",
    "        super(BERT, self).__init__()\n",
    "\n",
    "        self.num_embeddings = num_embeddings\n",
    "        self.num_transformer_block = num_transformer_block\n",
    "        self.num_enc_layers = num_enc_layers\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_attention = num_attention\n",
    "        self.hidden_channel = hidden_channel\n",
    "\n",
    "        self.embedding = BERTEmbeddingBlock(self.num_embeddings, self.embedding_dim)\n",
    "\n",
    "        self.transformer_blocks = nn.ModuleList(\n",
    "            [\n",
    "                TransformerEncoder(\n",
    "                    num_embeddings=self.embedding_dim,\n",
    "                    num_enc_layers=self.num_enc_layers,\n",
    "                    embedding_dim=self.embedding_dim,\n",
    "                    num_attention=self.num_attention,\n",
    "                    hidden_channel=self.hidden_channel,\n",
    "                    use_embedding=False,\n",
    "                )\n",
    "                for _ in range(self.num_transformer_block)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self, x, segment_info\n",
    "    ):  # referenced from https://github.com/codertimo/BERT-pytorch/blob/master/bert_pytorch/model/embedding/segment.py\n",
    "        x = self.embedding(x, segment_info)\n",
    "\n",
    "        for transformer in self.transformer_blocks:\n",
    "            x = transformer.forward(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "18a-H2UHFlRz"
   },
   "outputs": [],
   "source": [
    "patient_ques\n",
    "docter_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bQ30vNMeF6Ve"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1086,
     "status": "ok",
     "timestamp": 1701125507582,
     "user": {
      "displayName": "건건",
      "userId": "00925943111472079574"
     },
     "user_tz": 300
    },
    "id": "S5EiLugpF4qO",
    "outputId": "85a9a8f5-ecc9-4691-cf2f-7d81a25e4081"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "model = BERT(num_embeddings=len(tokenizer.word_index))\n",
    "print(sum(param.numel() for param in model.parameters()))\n",
    "\n",
    "input = \"hello friends?\"\n",
    "input = torch.randint(0, 3, (2, 3))  # num_embeddings:3  batch_size:2  max_len: 3\n",
    "segment_info = torch.tensor([[0, 0, 0], [1, 1, 1]], dtype=torch.int64)\n",
    "\n",
    "output = model(input, segment_info)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246
    },
    "executionInfo": {
     "elapsed": 493,
     "status": "error",
     "timestamp": 1701125508072,
     "user": {
      "displayName": "건건",
      "userId": "00925943111472079574"
     },
     "user_tz": 300
    },
    "id": "IO6GAK2zF7rx",
    "outputId": "95cb4792-875e-447c-c8f5-89f71415eba8"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "\n",
    "# Assuming pat_qus, doc_ans, seg_emb are already defined\n",
    "# and that your BERT model and ConversationDataset class are properly implemented\n",
    "\n",
    "# Create dataset and dataloader\n",
    "conversation_dataset = ConversationDataset(pat_qus, doc_ans, seg_emb)\n",
    "conversation_dataloader = DataLoader(\n",
    "    conversation_dataset, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "# Initialize the model\n",
    "model = BERT(num_embeddings=len(tokenizer.word_index))\n",
    "model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "loss_function = CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):  # num_epochs should be defined\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for i, data in enumerate(conversation_dataloader):\n",
    "        # Forward pass\n",
    "        patient_questions = data[\"patient_question\"].to(device)\n",
    "        doctor_answers = data[\"doctor_answer\"].to(device)\n",
    "        segment_embeddings = data[\"segment_embedding\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(patient_questions, segment_embeddings)[:, 201:, :]\n",
    "\n",
    "        # Compute loss - ensure doctor_answers is the correct target and has the right shape\n",
    "        loss = loss_function(output.view(-1, output.size(-1)), doctor_answers.view(-1))\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(conversation_dataloader)}\"\n",
    "    )\n",
    "\n",
    "# Optionally, you can add validation steps and model saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7UFM0bXT8uO7"
   },
   "outputs": [],
   "source": [
    "loss_function(output.view(-1, output.size(-1)), doctor_answers.view(-1))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
